{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-uiutyvql because the default path (/home/lfi/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model identifier: protT5-CLIP-2025-01-18-14-32-00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import accelerate\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from src._shared import (\n",
    "    apply_lora_to_model,\n",
    "    freeze_base_models,\n",
    "    load_clip_model,\n",
    "    load_config,\n",
    "    load_tokenizers,\n",
    "    prepare_dataset,\n",
    "    save_model_and_logs,\n",
    "    setup_environment,\n",
    "    setup_trainer,\n",
    "    train_model,\n",
    ")\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "train_config = load_config()\n",
    "model_name_identifier, device, report_to, run, USE_WANDB, SEED = setup_environment(train_config)\n",
    "\n",
    "accelerate.utils.set_seed(SEED + 1)\n",
    "transformers.set_seed(SEED + 2)\n",
    "torch.manual_seed(SEED + 3)\n",
    "random.seed(SEED + 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk...\n"
     ]
    }
   ],
   "source": [
    "tokenizer_plm, tokenizer_llm = load_tokenizers(train_config)\n",
    "dataset = prepare_dataset(train_config, tokenizer_plm, tokenizer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b195f1d7a00046409c3e23e712d65a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model...\n",
      "All model parameters are on CUDA\n"
     ]
    }
   ],
   "source": [
    "model = load_clip_model(train_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor(2.6592, device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0109, -0.0086, -0.0193,  ..., -0.0178,  0.0290, -0.0130],\n",
      "        [-0.0093, -0.0273,  0.0015,  ...,  0.0072, -0.0094, -0.0289],\n",
      "        [-0.0274, -0.0223, -0.0266,  ...,  0.0258, -0.0009, -0.0072],\n",
      "        ...,\n",
      "        [ 0.0085,  0.0016, -0.0294,  ...,  0.0262, -0.0267,  0.0040],\n",
      "        [-0.0139, -0.0153,  0.0166,  ...,  0.0137, -0.0211, -0.0101],\n",
      "        [ 0.0160,  0.0302,  0.0211,  ...,  0.0212,  0.0074, -0.0106]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0009,  0.0171,  0.0047,  ...,  0.0172,  0.0151,  0.0067],\n",
      "        [-0.0015, -0.0032, -0.0173,  ..., -0.0150, -0.0143, -0.0141],\n",
      "        [-0.0013, -0.0166, -0.0012,  ...,  0.0174,  0.0041, -0.0122],\n",
      "        ...,\n",
      "        [ 0.0145,  0.0071, -0.0127,  ...,  0.0121, -0.0071, -0.0050],\n",
      "        [ 0.0110,  0.0089, -0.0134,  ...,  0.0075, -0.0094, -0.0028],\n",
      "        [ 0.0069,  0.0146,  0.0052,  ...,  0.0052, -0.0143,  0.0054]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.logit_scale.scale)\n",
    "print(model.protein_projection.weight)\n",
    "print(model.text_projection.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_projections_from_safetensors('../tmp/models/protT5-CLIP-2025-01-17-21-47-10-0/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor(2.6643, device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0074, -0.0227, -0.0058,  ..., -0.0573,  0.0572,  0.0064],\n",
      "        [ 0.0138, -0.0352, -0.0175,  ..., -0.0012, -0.0031, -0.0709],\n",
      "        [ 0.0109,  0.0272, -0.0328,  ...,  0.0176, -0.0004,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0056, -0.0115,  0.0165,  ..., -0.0119, -0.0191,  0.0207],\n",
      "        [ 0.0204,  0.0111,  0.0314,  ..., -0.0556, -0.0031,  0.0595],\n",
      "        [ 0.0227,  0.0077,  0.0275,  ...,  0.0031, -0.0162, -0.0133]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.4211e-02,  2.6319e-03,  3.5704e-02,  ..., -5.5075e-02,\n",
      "          2.7038e-02,  2.0645e-02],\n",
      "        [-4.1908e-02, -2.2629e-02, -5.6813e-03,  ..., -4.8774e-02,\n",
      "         -4.0731e-02, -2.6518e-03],\n",
      "        [ 3.9049e-02, -2.5323e-02,  4.3649e-02,  ..., -2.4687e-02,\n",
      "         -2.8779e-02, -3.0384e-03],\n",
      "        ...,\n",
      "        [ 1.2926e-01,  2.1493e-02,  2.8456e-03,  ..., -5.8982e-03,\n",
      "          1.9103e-02, -3.6976e-02],\n",
      "        [ 4.1087e-02,  1.6181e-05, -1.7227e-03,  ..., -4.9684e-02,\n",
      "         -1.3508e-02, -1.5405e-02],\n",
      "        [ 5.6390e-02,  3.8532e-02,  2.2608e-02,  ...,  1.6730e-01,\n",
      "         -1.3233e-02,  6.8839e-02]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.logit_scale.scale)\n",
    "print(model.protein_projection.weight)\n",
    "print(model.text_projection.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
